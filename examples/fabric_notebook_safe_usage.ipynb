{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e0c304",
   "metadata": {},
   "source": [
    "# LakeTrace Logger - Safe Usage in Fabric Notebooks\n",
    "\n",
    "This notebook demonstrates conflict-free import patterns for Microsoft Fabric.\n",
    "\n",
    "## ‚úÖ Recommended Patterns (No Conflicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Safe factory function (RECOMMENDED)\n",
    "from laketrace import get_logger\n",
    "\n",
    "log = get_logger(\"fabric_notebook\")\n",
    "log.info(\"Notebook started\")\n",
    "log.info(\"Platform detected\", platform=\"fabric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 2: Direct class usage\n",
    "from laketrace import Logger\n",
    "\n",
    "log = Logger(\"fabric_notebook\")\n",
    "log.info(\"Using direct class instantiation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e594b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 3: Import with alias to avoid any conflicts\n",
    "from laketrace import get_logger as trace_logger\n",
    "\n",
    "log = trace_logger(\"fabric_notebook\")\n",
    "log.info(\"Using aliased import\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45202914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 4: Alternative factory function name\n",
    "from laketrace import create_logger\n",
    "\n",
    "log = create_logger(\"fabric_notebook\")\n",
    "log.info(\"Using create_logger alias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9b389d",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Existing Code Compatibility\n",
    "\n",
    "If your notebook already uses Python's standard logging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef3cf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Standard Python logger (existing code)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"Standard logging\")\n",
    "\n",
    "# LakeTrace logger (import with different name)\n",
    "from laketrace import get_logger\n",
    "trace_log = get_logger(\"my_job\")\n",
    "trace_log.info(\"LakeTrace logging\")\n",
    "\n",
    "# Both work independently - no conflicts!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f5bb1b",
   "metadata": {},
   "source": [
    "## üìù Context Binding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b477b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laketrace import get_logger\n",
    "\n",
    "# Create logger with custom config\n",
    "log = get_logger(\n",
    "    \"etl_pipeline\",\n",
    "    config={\n",
    "        \"log_dir\": \"/lakehouse/default/Files/logs\",\n",
    "        \"json\": True,\n",
    "        \"level\": \"INFO\",\n",
    "        \"rotation_mb\": 10,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Bind context for structured logging\n",
    "stage_log = log.bind(stage=\"extract\", dataset=\"sales\")\n",
    "stage_log.info(\"Starting extraction\", record_count=10000)\n",
    "\n",
    "# Nested context\n",
    "table_log = stage_log.bind(table=\"fact_sales\")\n",
    "table_log.info(\"Processing table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01905dae",
   "metadata": {},
   "source": [
    "## üîç Runtime Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c75002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laketrace import get_logger, detect_runtime\n",
    "\n",
    "# Detect platform automatically\n",
    "runtime = detect_runtime()\n",
    "print(f\"Platform: {runtime.platform.value}\")\n",
    "print(f\"Runtime Type: {runtime.runtime_type.value}\")\n",
    "print(f\"Hostname: {runtime.hostname}\")\n",
    "\n",
    "# Logger includes this context automatically\n",
    "log = get_logger(\"my_job\")\n",
    "log.info(\"Runtime context included in logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49274f6",
   "metadata": {},
   "source": [
    "## üì§ Upload Logs to Lakehouse (End of Notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6508d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laketrace import get_logger\n",
    "from datetime import datetime\n",
    "\n",
    "log = get_logger(\"my_notebook\")\n",
    "\n",
    "# ... do work ...\n",
    "log.info(\"Processing completed\")\n",
    "\n",
    "# At end of notebook, upload logs\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "target_path = f\"Files/logs/my_notebook_{timestamp}.log\"\n",
    "\n",
    "success = log.upload_log_to_lakehouse(target_path)\n",
    "if success:\n",
    "    print(f\"‚úÖ Logs uploaded to: {target_path}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Log upload failed (check local file)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a7b50",
   "metadata": {},
   "source": [
    "## üõ°Ô∏è Safety Features\n",
    "\n",
    "### No Conflicts\n",
    "- `get_logger()` doesn't conflict with `logging.getLogger()`\n",
    "- Can coexist with standard Python logging\n",
    "- Won't override existing `logger` variables\n",
    "\n",
    "### Notebook Re-execution Safe\n",
    "- Handlers automatically reset on re-init\n",
    "- No duplicate log entries\n",
    "- Thread-safe for concurrent execution\n",
    "\n",
    "### Spark-Safe\n",
    "- Designed for driver-only logging\n",
    "- No remote file writes during execution\n",
    "- Upload only at end-of-run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a831db",
   "metadata": {},
   "source": [
    "## üìä View Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2727d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laketrace import get_logger\n",
    "\n",
    "log = get_logger(\"my_job\")\n",
    "\n",
    "# Print last 50 lines of log\n",
    "log.tail(50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
